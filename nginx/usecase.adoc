= Nginx Plus Use Case
:toc: manual

== 基础配置

=== 自定义欢迎页面

[cols="2,5a"]
|===
|ITEM |NOTE

|目的
|验证自定制默认欢迎页面

|步骤
|
* 访问默认欢迎页面(http://192.168.100.71/)

image:img/nginx-default-welcomepage.png[]

* 自定义欢迎页面

----
echo "Hello Nginx" > /usr/share/nginx/html/index.html
----

* 自定义测试界面

----
echo "ok" > /usr/share/nginx/html/hello
----

|结果
|

[source, bash]
.*访问默认欢迎页面*
----
$ curl http://192.168.100.71
Hello Nginx
----

[source, bash]
.*访问定制测试页面*
----
$ curl http://192.168.100.71/hello
ok
----
|===

=== API 及 Dashboard 能力

[cols="2,5a"]
|===
|ITEM |NOTE

|目的
|Nginx Plus 具备 API 能力以及 Dashboard 能力，可视化展示 Nginx Plus 自身及应用交付的状态。

|步骤
|
[source, bash]
.*备份默认配置*
----
mv /etc/nginx/conf.d/default.conf /etc/nginx/conf.d/default.conf.bak.$(date "+%Y%m%d%H%M%S")
----

[source, bash]
.*新建 default.conf 文件*
----
cat << EOF > /etc/nginx/conf.d/default.conf
server {
    listen 8081;
    location /api {
      # limit_except GET {
      #    auth_basic "NGINX Plus API";
      #    auth_basic_user_file /path/to/passwd/file;
      # }
       api write=on;
        #access_log off;
    }

    location = /dashboard.html {
        root   /usr/share/nginx/html;
        access_log off;
    }
    location /swagger-ui {
        root   /usr/share/nginx/html;
    }
}
EOF
----

[source, bash]
.*重新加载*
----
nginx -s reload
----

|结果
|
* API - http://192.168.100.71:8081/swagger-ui/

image:img/nginx-api.png[]

* Dashboard - http://192.168.100.71:8081/dashboard.html

image:img/nginx-dashboard.png[]
|===

== 负载均衡

=== 轮询负载算法

[cols="2,5a"]
|===
|ITEM |NOTE

|目的
|Nginx Plus 支持轮询的调度算法

|步骤
|
[source, bash]
.*默认算法为轮询，新建配置文件rr.conf*
----
cat << EOF > /etc/nginx/conf.d/rr.conf
upstream backend {
  zone upstream_backend 64k;
  server 10.1.10.6:8080;
  server 10.1.10.7:8080;
  server 10.1.10.8:8080;
}
server {
  listen 8082;
  status_zone server_backend;
  location / {
    status_zone location_backend;
    proxy_pass http://backend;
  }
}
EOF
----

[source, bash]
.*重新加载*
----
nginx -s reload
----

|结果
|

[source, bash]
.*命令行访问测试*
----
$ for i in {1..100} ; do curl http://192.168.100.71:8082/ -s ; done
    Server Hostname: server-1
    Server Hostname: server-2
    Server Hostname: server-3
    Server Hostname: server-1
    Server Hostname: server-2
    Server Hostname: server-3
----

*Dashboard 上查看统计数据*

image:img/nginx-lb-rr.png[]

|===

=== 最小连接数负载算法

[cols="2,5a"]
|===
|ITEM |NOTE

|目的
|Nginx Plus 支持最小连接数的调度算法

|步骤
|
[source, bash]
.*新建配置文件 least.conf*
----
cat << EOF > /etc/nginx/conf.d/least.conf
upstream backendLeast {
  zone upstream_backend 64k;
  least_conn;
  server 10.1.10.6:8080;
  server 10.1.10.7:8080;
  server 10.1.10.8:8080;
}
server {
  listen 8083;
  status_zone server_backend;
  location / {
    status_zone location_backend;
    proxy_pass http://backendLeast;
  }
}
EOF
----

[source, bash]
.*重新加载*
----
nginx -s reload
---- 

|结果
|

[source, bash]
.*命令行访问测试*
----
$ for i in {1..100} ; do curl http://192.168.100.71:8083/ -s ; done
    Server Hostname: server-1
    Server Hostname: server-2
    Server Hostname: server-3
    Server Hostname: server-1
    Server Hostname: server-2
    Server Hostname: server-3
----

*Dashboard 上查看统计数据*

image:img/nginx-lb-least.png[]

|===

=== 权重与优先级负载算法

[cols="2,5a"]
|===
|ITEM |NOTE

|目的
|Nginx Plus 支持权重优先级的调度算法

|步骤
|
[source, bash]
.*新建配置文件 weight.conf*
----
cat << EOF > /etc/nginx/conf.d/weight.conf
upstream backendWeight {
  zone upstream_backend 64k;
  server 10.1.10.6:8080 weight=5;
  server 10.1.10.7:8080 weight=2;
  server 10.1.10.8:8080 backup;
}
server { 
  listen 8084;
  status_zone server_backend;
  location / {
    status_zone location_backend;
    proxy_pass http://backendWeight;
  }
}
EOF
----

[source, bash]
.*重新加载*
----
nginx -s reload
----
|结果
|
[source, bash]
.*命令行访问测试*
----
$ for i in {1..100} ; do curl http://192.168.100.71:8084/ -s ; done
    Server Hostname: server-1
    Server Hostname: server-2
    Server Hostname: server-1
    Server Hostname: server-1
    Server Hostname: server-1
    Server Hostname: server-2
    Server Hostname: server-1
    Server Hostname: server-1
----

*Dashboard 上查看统计数据*

image:img/nginx-lb-weight.png[]

|===

=== IP 哈希负载算法

[cols="2,5a"]
|===
|ITEM |NOTE

|目的
|Nginx Plus 支持 IP 哈希调度算法

|步骤
|
[source, bash]
.*新建配置文件 iphash.conf*
----
cat << EOF > /etc/nginx/conf.d/iphash.conf
upstream backendIPHash {
  zone upstream_backend 64k;
  ip_hash;
  server 10.1.10.6:8080 ;
  server 10.1.10.7:8080 ;
  server 10.1.10.8:8080 down;
}
server {
  listen 8085;
  status_zone server_backend;
  location / {
    status_zone location_backend;
    proxy_pass http://backendIPHash;
  }
}
EOF
----

[source, bash]
.*重新加载*
----
nginx -s reload
----

|结果
|
[source, bash]
.*命令行访问测试*
----
$ for i in {1..100} ; do curl http://192.168.100.71:8085/ -s ; done
    Server Hostname: server-2
    Server Hostname: server-2
    Server Hostname: server-2
    Server Hostname: server-2
    Server Hostname: server-2
    Server Hostname: server-2
    Server Hostname: server-2
----

*Dashboard 上查看统计数据*

image:img/nginx-lb-iphash.png[]
|===

=== 被动健康检查

[cols="2,5a"]
|===
|ITEM |NOTE

|目的
|Nginx Plus 支持被动的健康检查

|步骤
|
[source, bash]
.*新建配置文件 health.conf*
----
cat << EOF > /etc/nginx/conf.d/health.conf
upstream backendHealth {
  zone upstream_backend 64k;
  server 10.1.10.6:8080 max_fails=3 fail_timeout=30s;
  server 10.1.10.7:8080 max_fails=3 fail_timeout=30s;
  server 10.1.10.8:8080 max_fails=3 fail_timeout=30s;
}
server {
  listen 8086;
  status_zone server_backend;
  location / {
    status_zone location_backend;
    proxy_pass http://backendHealth;
  }
}
EOF
----

[source, bash]
.*重新加载*
----
nginx -s reload
----

*关闭服务 10.1.10.8:8080*

|结果
|
[source, bash]
.*命令行访问测试*
----
$ for i in {1..100} ; do curl http://192.168.100.71:8086/ -s  ; done
    Server Hostname: server-1
    Server Hostname: server-2
    Server Hostname: server-1
    Server Hostname: server-2
    Server Hostname: server-1
    Server Hostname: server-2
----

*Dashboard 上查看统计数据*

image:img/nginx-lb-health.png[]

|===

=== 基于 HTTP 的主动健康检查

[cols="2,5a"]
|===
|ITEM |NOTE

|目的
|Nginx Plus 支持基于 HTTP 的主动健康检查

|步骤
|
[source, bash]
.*新建配置文件 healthHTTP.conf*
----
cat << EOF > /etc/nginx/conf.d/healthHTTP.conf
upstream backendHelthHTTP {
  zone upstream_backend 64k;
  server 10.1.10.6:8080 ;
  server 10.1.10.7:8080 ;
  server 10.1.10.8:8080 ;
}

match server_ok {
  status 200-399;
  body ~ "ok";
}

server {
  listen 8087;
  status_zone server_backend;
  location / {
    status_zone location_backend;
    proxy_pass http://backendHelthHTTP;
    health_check uri=/health match=server_ok interval=10 fails=3 passes=1;
  }
}
EOF
----

[source, bash]
.*重新加载*
----
nginx -s reload
----

*关闭服务 10.1.10.8:8080*

|结果
|

* 等待 30 秒后，在 Dashboard 上查看统计数据

image:img/nginx-lb-health-http.png[]

* 启动服务 10.1.10.8:8080

* 等待 10 秒左右，在 Dashboard 上查看统计数据

image:img/nginx-lb-health-http-recover.png[]

|===

=== 基于 Cookie 的会话保持

[cols="2,5a"]
|===
|ITEM |NOTE

|目的
|Nginx Plus 支持基于 Cookie 的会话保持

|步骤
|
[source, bash]
.*新建配置文件 persisCookie.conf*
----
cat << EOF > /etc/nginx/conf.d/persisCookie.conf
upstream backendCookie {
  zone upstream_backend 64k;
  server 10.1.10.6:8080 ;
  server 10.1.10.7:8080 ;
  server 10.1.10.8:8080 ;
  sticky cookie srv_id expires=1h path=/;
}

server {
  listen 8088;
  status_zone server_backend;
  location / { 
    status_zone location_backend;
    proxy_pass http://backendCookie;
    health_check interval=10 fails=3 passes=1;
  }
}
EOF
----

[source, bash]
.*重新加载*
----
nginx -s reload
----

|结果
|

* 浏览器访问服务多次，验证会话保持能力，及查看HTTP头中 srv_id Cookie

image:img/nginx-lb-persist-cookie.png[]

* 在 Dashboard 上查看统计数据

image:img/nginx-lb-persist-cookie-db.png[]

|===

== 内容缓存

[cols="2,5a"]
|===
|ITEM |NOTE

|目的
|Nginx Plug 内容缓存能力

|步骤
|
[source, bash]
.*新建 cache.conf 文件*
----
cat << EOF > /etc/nginx/conf.d/cache.conf
EOF
----

[source, bash]
.*重新加载*
----
nginx -s reload
----

|结果
|

|===

== 性能优化

=== 性能调优一般步骤

[cols="5a,5a"]
|===
|ITEM |NOTE

|目的
|本部分验证性能调优的一般步骤，以及不同步骤对 Nginx 性能的影响。

验证拓扑如下：

* 客户端：wrk软件
* 反向代理：性能优化对象
* Web端：NGINX

以上所有节点规格都是 2C 4G。

|OS 参数调优
|link:file/proc.bash[资源限制设定]

|默认配置性能
|
[source, bash]
.*配置备份*
----
mv /etc/nginx/nginx.conf /etc/nginx/nginx.conf.bak.$(date "+%Y%m%d%H%M%S")
----

[source, bash]
.*默认配置文件 /etc/nginx/nginx.conf*
----
user  nginx;
worker_processes  1;

error_log  /var/log/nginx/error.log notice;
pid        /var/run/nginx.pid;


events {
    worker_connections  1024;
}


http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;

    sendfile        on;

    keepalive_timeout  65;


    include /etc/nginx/conf.d/*.conf;
}
----

[source, bash]
.*Server 配置*
----
cat << EOF > /etc/nginx/conf.d/app.conf
upstream webserver {
  zone upstream_backend 64k;
  server 192.168.71.210:80;
}


server {
  listen 9082;
  status_zone server_backend;
  location / {
    status_zone location_backend;
    proxy_pass http://webserver;
  }
}
EOF
----

[source, bash]
.*WRK 结果*
----
$ wrk -t4 -c800 -d120s http://192.168.71.211:9082
Running 2m test @ http://192.168.71.211:9082
  4 threads and 800 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   161.53ms  298.21ms   2.00s    86.69%
    Req/Sec     2.58k   502.22     6.53k    74.94%
  1230598 requests in 2.00m, 0.97GB read
  Socket errors: connect 0, read 49589, write 0, timeout 1933
Requests/sec:  10249.33
Transfer/sec:      8.31MB
----

*Dashboard UI 上统计信息*

image:img/nginx-perf-1.serverZone.png[]

|优化连接数限制
|

[source, bash]
.*修改 worker_connections 从默认 1024 到 10000*
----
user  nginx;
worker_processes  1;

worker_rlimit_nofile 30000;

error_log  /var/log/nginx/error.log notice;
pid        /var/run/nginx.pid;


events {
    worker_connections  100000;
}
----

[source, bash]
.*WRK 测试结果*
----
$ wrk -t4 -c800 -d120s http://192.168.71.211:9082
Running 2m test @ http://192.168.71.211:9082
  4 threads and 800 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   177.90ms  294.22ms   2.00s    85.21%
    Req/Sec     2.58k   585.26     6.92k    76.87%
  1231828 requests in 2.00m, 0.98GB read
  Socket errors: connect 0, read 0, write 0, timeout 1255
Requests/sec:  10262.24
Transfer/sec:      8.32MB
----

|优化 worker 数量 
|

[source, bash]
.*修改 worker_processes 从 1 到 auto*
----
user  nginx;
worker_processes  auto;

worker_rlimit_nofile 30000;

error_log  /var/log/nginx/error.log notice;
pid        /var/run/nginx.pid;


events {
    worker_connections  100000;
}
----

[source, bash]
.*WRK 测试结果*
----
$ wrk -t4 -c800 -d120s http://192.168.71.211:9082
Running 2m test @ http://192.168.71.211:9082
  4 threads and 800 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   233.65ms  343.01ms   1.83s    80.99%
    Req/Sec     3.43k   613.32     6.02k    70.40%
  1637802 requests in 2.00m, 1.30GB read
  Socket errors: connect 0, read 0, write 0, timeout 4351
Requests/sec:  13643.47
Transfer/sec:     11.06MB
----

|连接复用
|
[source, bash]
.*配置连接复用*
----
upstream webserver {
  zone upstream_backend 64k;
  server 192.168.71.210:80;
  keepalive 128;
}

server {
  listen 9082;
  status_zone server_backend;
  location / {
    status_zone location_backend;
    proxy_pass http://webserver;
    proxy_http_version 1.1;
    proxy_set_header Connection "";
  }
}
----

[source, bash]
.*WRK 测试结果*
----
wrk -t4 -c800 -d120s http://192.168.71.211:9082
Running 2m test @ http://192.168.71.211:9082
  4 threads and 800 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   103.88ms  285.25ms   2.00s    90.34%
    Req/Sec     5.82k     1.25k   14.52k    69.75%
  2779426 requests in 2.00m, 2.20GB read
  Socket errors: connect 0, read 0, write 0, timeout 6382
  Non-2xx or 3xx responses: 249
Requests/sec:  23155.66
Transfer/sec:     18.77MB
----

|CPU亲和及worker优先级
|
[source, bash]
.*配置*
----
user  nginx;
worker_processes  2;
worker_cpu_affinity 0101 1010;

worker_rlimit_nofile 30000;

error_log  /var/log/nginx/error.log notice;
pid        /var/run/nginx.pid;
worker_priority -20;
----

[source, bash]
.*WRK 测试结果*
----
wrk -t4 -c800 -d120s http://192.168.71.211:9082
Running 2m test @ http://192.168.71.211:9082
  4 threads and 800 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    97.73ms  277.42ms   2.00s    90.52%
    Req/Sec     5.01k     1.46k   15.75k    78.92%
  2391712 requests in 2.00m, 1.89GB read
  Socket errors: connect 0, read 0, write 0, timeout 5774
  Non-2xx or 3xx responses: 446
Requests/sec:  19924.37
Transfer/sec:     16.15MB
----

|日志缓存 
|
[source, bash]
.*配置*
----
http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main buffer=1m;
----

[source, bash]
.*WRK 测试结果*
----
wrk -t4 -c800 -d120s http://192.168.71.211:9082
Running 2m test @ http://192.168.71.211:9082
  4 threads and 800 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   101.26ms  281.45ms   2.00s    90.36%
    Req/Sec     5.69k     1.36k   18.52k    73.07%
  2716274 requests in 2.00m, 2.15GB read
  Socket errors: connect 0, read 0, write 0, timeout 6294
  Non-2xx or 3xx responses: 460
Requests/sec:  22617.47
Transfer/sec:     18.33MB
----

|Cache
|
[source, bash]
.*配置*
----
upstream webserver {
  zone upstream_backend 64k;
  server 192.168.71.210:80;
  keepalive 128;
}

proxy_cache_path /tmp/cache keys_zone=mycache:10m inactive=60m;

server {
  listen 9082;
  status_zone server_backend;
  location / {
    status_zone location_backend;
    proxy_pass http://webserver;
    proxy_http_version 1.1;
    proxy_set_header Connection "";
    proxy_cache_key $host:$server_port$request_uri;
    proxy_cache_valid 200 304 1h;
    proxy_cache mycache;
  }
}
----

[source, bash]
.*WRK 测试结果*
----
wrk -t4 -c800 -d120s http://192.168.71.211:9082
Running 2m test @ http://192.168.71.211:9082
  4 threads and 800 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    40.12ms  127.31ms   1.95s    91.85%
    Req/Sec    12.16k     2.64k   27.87k    75.58%
  5806262 requests in 2.00m, 4.60GB read
  Socket errors: connect 0, read 189, write 0, timeout 275
Requests/sec:  48372.99
Transfer/sec:     39.21MB
----

|===


[cols="2,5a"]
|===
|ITEM |NOTE

|目的
|

|步骤
|

|结果
|

|===

[cols="2,5a"]
|===
|ITEM |NOTE

|目的
|

|步骤
|

|结果
|

|===


[cols="2,5a"]
|===
|ITEM |NOTE

|目的
|

|步骤
|

|结果
|

|===

[cols="2,5a"]
|===
|ITEM |NOTE

|目的
|

|步骤
|

|结果
|

|===


[cols="2,5a"]
|===
|ITEM |NOTE

|目的
|

|步骤
|

|结果
|

|===

[cols="2,5a"]
|===
|ITEM |NOTE

|目的
|

|步骤
|

|结果
|

|===


[cols="2,5a"]
|===
|ITEM |NOTE

|目的
|

|步骤
|

|结果
|

|===


[source,bash]
.**
----

----

